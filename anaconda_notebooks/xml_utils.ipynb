{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST!\n",
    "\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "\n",
    "test = {}\n",
    "for app in tree.iter('app'):\n",
    "    try:\n",
    "        if app.xpath('.//number_of_players')[0].text != None:\n",
    "            if app.get('scraped') != '1':\n",
    "                test[app.get('id')] = int(app.xpath('.//number_of_players')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sorted(test.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tags test. i'm worried that there will be many cases of almost identical tags.\n",
    "#but apparently that's not the case\n",
    "#cartoon - cartoony\n",
    "\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "    \n",
    "tags = {}\n",
    "\n",
    "for tag in tree.iter('tag'):\n",
    "    if tag.text in list(tags.keys()):\n",
    "        tags[tag.text] += 1\n",
    "    else:\n",
    "        tags[tag.text] = 1\n",
    "    \n",
    "    \n",
    "sorted(tags.items(), key=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize from http://api.steampowered.com/ISteamApps/GetAppList/v0001/\n",
    "# WARNING: THIS WILL WIPE ALL DATA\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "from lxml import etree\n",
    "\n",
    "request = 'http://api.steampowered.com/ISteamApps/GetAppList/v0001/'\n",
    "response = requests.get(request)\n",
    "if len(response.text)<1000:\n",
    "    sys.exit(\"something wrong with request\")\n",
    "json_response = json.loads(response.text)\n",
    "root = etree.Element(\"root\")\n",
    "for r_app in json_response['applist']['apps']['app']:\n",
    "    app = etree.SubElement(root, 'app')\n",
    "    app.set('id',str(r_app['appid']))\n",
    "    name = etree.SubElement(app, 'name')\n",
    "    name.text = str(r_app['name'])\n",
    "tree = etree.ElementTree(root)\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'wb') as f:\n",
    "    f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# append data from _appids_scrapped files:\n",
    "# it's a file of api responses\n",
    "# requests = appids found in users libraries\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_appids_scraped.json\", 'r') as f:\n",
    "    json_data = json.loads(f.read())\n",
    "\n",
    "for app in json_data:\n",
    "    requested_app = None\n",
    "    \n",
    "    for xml_app in tree.iter('app'):\n",
    "        if xml_app.get('id') == app['appid']:\n",
    "            requested_app = xml_app\n",
    "            break\n",
    "    if requested_app == None:\n",
    "        print(app, 'not in xml')\n",
    "        continue\n",
    "    \n",
    "    requested_app.set('scraped', '1')\n",
    "    \n",
    "    for key in list(app.keys()):\n",
    "        if key == 'requested_appid': # id as it was requested by scraper, not as was given in response\n",
    "            if app['requested_appid'] != app['appid']:\n",
    "                query = requested_app.xpath(\".//redirected_from\")\n",
    "                if len(query) == 0:\n",
    "                    sub = etree.SubElement(requested_app, 'redirected_from')\n",
    "                else:\n",
    "                    sub = query[0]\n",
    "                red_id = etree.SubElement(sub, 'redirected_from')\n",
    "                red_id.text = app['requested_appid']\n",
    "                \n",
    "                # then flag the original:\n",
    "                app_to_flag = None\n",
    "                for xml_app2 in tree.iter('app'):\n",
    "                    if xml_app2.get('id') == app['requested_appid']:\n",
    "                        app_to_flag = xml_app2\n",
    "                        break\n",
    "                if app_to_flag == None:\n",
    "                    print(app['requested_appid'], 'not in xml')\n",
    "                    continue\n",
    "                app_to_flag.set('redirects_to_id',app['requested_appid'])\n",
    "        \n",
    "        elif key == 'title': # title as scraped\n",
    "            #name from json?\n",
    "            if requested_app.xpath(\".//name\")[0].text != app['title']:\n",
    "                query = requested_app.xpath(\".//name_scraped\")\n",
    "                if len(query) == 0:\n",
    "                    sub = etree.SubElement(requested_app, 'name_scraped')\n",
    "                else:\n",
    "                    sub = query[0]\n",
    "                sub.text = str(app['title'])\n",
    "                #print(\"names don't match! found in xml:\",requested_app.xpath(\".//name\")[0].text,'found in json:', app['title'])\n",
    "\n",
    "        elif key == 'release_date': # it's a list\n",
    "            query = requested_app.xpath(\".//release_date\")\n",
    "            if len(query) == 0:\n",
    "                sub = etree.SubElement(requested_app, 'release_date')\n",
    "            else:\n",
    "                sub = query[0]\n",
    "            try:\n",
    "                date = app['release_date'][0]\n",
    "                # let's reformat date to YYYY-MM-DD format\n",
    "                try:\n",
    "                    date_formatted = datetime.datetime.strptime(date, \"%d %b, %Y\").strftime(\"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        date_formatted = datetime.datetime.strptime(date, \"%b %Y\").strftime(\"%Y-%m-%d\")\n",
    "                    except ValueError: #wrong date format\n",
    "                        date_formatted = None\n",
    "            except IndexError: #sometimes there's no date\n",
    "                date_formatted = None\n",
    "            sub.text = date_formatted\n",
    "                \n",
    "        elif key == 'price': # price in EUR, it's a list\n",
    "            query = requested_app.xpath(\".//price\")\n",
    "            if len(query) == 0:\n",
    "                sub = etree.SubElement(requested_app, 'price')\n",
    "            else:\n",
    "                sub = query[0]\n",
    "            try:\n",
    "                price = app['price'][0]\n",
    "            except IndexError: # sometimes there's no price\n",
    "                price = None\n",
    "            sub.text = price\n",
    "            if price != None:\n",
    "                price = price.replace(',','.')\n",
    "                if price != '0.00':\n",
    "                    sub.set('currency', app['price_currency'][0])\n",
    "            \n",
    "        elif key == 'developer': # may contain several developers, it's the same for and publishers and tags\n",
    "            query = requested_app.xpath(\".//developers\")\n",
    "            if len(query) != 0:\n",
    "                sub = query[0]\n",
    "                requested_app.remove(sub)\n",
    "            sub = etree.SubElement(requested_app, 'developers')\n",
    "            for dev_name in app['developer']:\n",
    "                dev_name = dev_name.title()\n",
    "                dev_sub = etree.SubElement(sub, 'developer')\n",
    "                dev_sub.text = dev_name\n",
    "                \n",
    "        elif key == 'publisher':\n",
    "            query = requested_app.xpath(\".//publishers\")\n",
    "            if len(query) != 0:\n",
    "                sub = query[0]\n",
    "                requested_app.remove(sub)\n",
    "            sub = etree.SubElement(requested_app, 'publishers')\n",
    "            for pub_name in app['publisher']:\n",
    "                pub_name = pub_name.title()\n",
    "                pub_sub = etree.SubElement(sub, 'publisher')\n",
    "                pub_sub.text = pub_name\n",
    "                \n",
    "        elif key == 'tags':\n",
    "            query = requested_app.xpath(\".//tags\")\n",
    "            if len(query) != 0:\n",
    "                sub = query[0]\n",
    "                requested_app.remove(sub)\n",
    "            sub = etree.SubElement(requested_app, 'tags')\n",
    "            for tag_name in app['tags']:\n",
    "                tag_name = tag_name.title()\n",
    "                tag_sub = etree.SubElement(sub, 'tag')\n",
    "                tag_sub.text = tag_name\n",
    "                \n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'wb') as f:\n",
    "    f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# append data from scraped_meta files:\n",
    "# these are meta files generated when scraping users\n",
    "# they contain values regarding number of users playing specific game etc\n",
    "\n",
    "import json\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\profiles0_scraped_meta.txt\", 'r') as f:\n",
    "    json_data = json.loads(f.read())\n",
    "    \n",
    "for app in json_data:\n",
    "    \n",
    "    requested_app = None\n",
    "    \n",
    "    # does this app exist in xml?\n",
    "    # query = tree.xpath(\"//app[@id=\"+app+\"]\")  is apparently slower\n",
    "    for xml_app in tree.iter('app'):\n",
    "        if xml_app.get('id') == app:\n",
    "            requested_app = xml_app\n",
    "            break\n",
    "    if requested_app == None:\n",
    "        print(app,'not in xml')\n",
    "        continue\n",
    "    \n",
    "    for key in list(json_data[app].keys()):\n",
    "        if key == 'number': # number of players\n",
    "            query = requested_app.xpath(\".//number_of_players\")\n",
    "            if len(query) == 0:\n",
    "                sub = etree.SubElement(requested_app, 'number_of_players')\n",
    "                sub.text = str(json_data[app]['number'])\n",
    "            else:\n",
    "                sub = query[0]\n",
    "                sub.text = str(int(sub.text) + json_data[app]['number'])\n",
    "        elif key == 'user': # last user from which the data was collected\n",
    "            query = requested_app.xpath(\".//found_in_user\")\n",
    "            if len(query) == 0:\n",
    "                sub = etree.SubElement(requested_app, 'found_in_user')\n",
    "            else:\n",
    "                sub = query[0]\n",
    "            sub.text = str(json_data[app]['user'])\n",
    "        elif key == 'total_playtime': # total playtime of all users\n",
    "            query = requested_app.xpath(\".//total_playtime\")\n",
    "            if len(query) == 0:\n",
    "                sub = etree.SubElement(requested_app, 'total_playtime')\n",
    "                sub.text = str(json_data[app]['total_playtime'])\n",
    "            else:\n",
    "                sub = query[0]\n",
    "                sub.text = str(int(sub.text) + json_data[app]['total_playtime'])\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'wb') as f:\n",
    "    f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# color from PCA to color generation\n",
    "\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "from colormath.color_objects import sRGBColor # https://anaconda.org/melund/colormath\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_colors_from_pca.csv\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if len(line)<10:\n",
    "            continue\n",
    "        line = line.strip(\"\\n\") # appid10170,0.0,0.0196078431372549,0.4\n",
    "        split = line.split(',')\n",
    "        if len(split)!=4:\n",
    "            print('line seems errorenous:',line)\n",
    "            continue\n",
    "        app = split[0]\n",
    "        app = app.strip('appid')\n",
    "        color_from_pca = sRGBColor(split[1],split[2],split[3]).get_rgb_hex()\n",
    "        #color_from_pca = colour.rgb2hex((split[1],split[2],split[3]))\n",
    "        \n",
    "        #find app\n",
    "        requested_app = None\n",
    "        for xml_app in tree.iter('app'):\n",
    "            if xml_app.get('id') == app:\n",
    "                requested_app = xml_app\n",
    "                break\n",
    "        if requested_app == None:\n",
    "            print(app,'not in xml')\n",
    "            continue\n",
    "            \n",
    "        query = requested_app.xpath(\".//colors\")\n",
    "        if len(query) == 0:\n",
    "            sub = etree.SubElement(requested_app, 'colors')\n",
    "        else:\n",
    "            sub = query[0]\n",
    "        query = sub.xpath(\".//color[@type='pca']\")\n",
    "        if len(query) == 0:\n",
    "            color = etree.SubElement(sub, 'color')\n",
    "            color.set('type','pca')\n",
    "        else:\n",
    "            color = query[0]\n",
    "        color.text = color_from_pca\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'wb') as f:\n",
    "    f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a 'standardized size' field which takes in number of players and distributes it between 0 and 1\n",
    "# in such a way that they're equally distributed\n",
    "\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "\n",
    "numbers = []\n",
    "\n",
    "for sub in tree.iter('number_of_players'):\n",
    "    numbers.append(math.log(int(sub.text)))\n",
    "amin = np.amin(numbers)\n",
    "amax = np.amax(numbers)\n",
    "\n",
    "for app in tree.iter('app'):\n",
    "    query = app.xpath(\".//number_of_players\")\n",
    "    if len(query) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        sub = query[0]\n",
    "    standardized_size = math.log(int(sub.text))\n",
    "    standardized_size = (standardized_size - amin)/(amax - amin)\n",
    "    print(sub.text, standardized_size)\n",
    "    \n",
    "    query = app.xpath(\".//node_sizes\")\n",
    "    if len(query) == 0:\n",
    "        sub = etree.SubElement(app, 'node_sizes')\n",
    "    else:\n",
    "        sub = query[0]\n",
    "    query = app.xpath(\".//size[@type='std_number_of_players']\")\n",
    "    if len(query) == 0:\n",
    "        sub2 = etree.SubElement(sub, 'size')\n",
    "    else:\n",
    "        sub2 = query[0]\n",
    "    sub2.set('type','std_number_of_players')\n",
    "    sub2.text = str(standardized_size)\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'wb') as f:\n",
    "    f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump all ids into one file (to have something to scrap with appdata_from_appids_spider.py)\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_appids_from_xml.txt', 'w') as f:\n",
    "    for app in tree.iter('app'):\n",
    "        appid = app.get('id')\n",
    "        f.write(appid+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items: 9537\n",
      "progress: 1.04%\n",
      "progress: 2.09%\n",
      "progress: 3.14%\n",
      "progress: 4.18%\n",
      "progress: 5.23%\n",
      "progress: 6.28%\n",
      "progress: 7.33%\n",
      "progress: 8.38%\n",
      "progress: 9.43%\n",
      "progress: 10.47%\n",
      "progress: 11.52%\n",
      "progress: 12.57%\n",
      "progress: 13.62%\n",
      "progress: 14.67%\n",
      "progress: 15.72%\n",
      "progress: 16.77%\n",
      "progress: 17.81%\n",
      "progress: 18.86%\n",
      "progress: 19.91%\n",
      "progress: 20.96%\n",
      "progress: 22.01%\n",
      "progress: 23.06%\n",
      "progress: 24.11%\n",
      "progress: 25.15%\n",
      "progress: 26.20%\n",
      "progress: 27.25%\n",
      "progress: 28.30%\n",
      "progress: 29.35%\n",
      "progress: 30.40%\n",
      "progress: 31.45%\n",
      "progress: 32.49%\n",
      "progress: 33.54%\n",
      "progress: 34.59%\n",
      "progress: 35.64%\n",
      "progress: 36.69%\n",
      "progress: 37.74%\n",
      "progress: 38.79%\n",
      "progress: 39.83%\n",
      "progress: 40.88%\n",
      "progress: 41.93%\n",
      "progress: 42.98%\n",
      "progress: 44.03%\n",
      "progress: 45.08%\n",
      "progress: 46.13%\n",
      "progress: 47.17%\n",
      "progress: 48.22%\n",
      "progress: 49.27%\n",
      "progress: 50.32%\n",
      "progress: 51.37%\n",
      "progress: 52.42%\n",
      "progress: 53.47%\n",
      "progress: 54.51%\n",
      "progress: 55.56%\n",
      "progress: 56.61%\n",
      "progress: 57.66%\n",
      "progress: 58.71%\n",
      "progress: 59.76%\n",
      "progress: 60.81%\n",
      "progress: 61.85%\n",
      "progress: 62.90%\n",
      "progress: 63.95%\n",
      "progress: 65.00%\n",
      "progress: 66.05%\n",
      "progress: 67.10%\n",
      "progress: 68.15%\n",
      "progress: 69.19%\n",
      "progress: 70.24%\n",
      "progress: 71.29%\n",
      "progress: 72.34%\n",
      "progress: 73.39%\n",
      "progress: 74.44%\n",
      "progress: 75.48%\n",
      "progress: 76.53%\n",
      "progress: 77.58%\n",
      "progress: 78.63%\n",
      "progress: 79.68%\n",
      "progress: 80.73%\n",
      "progress: 81.78%\n",
      "progress: 82.82%\n",
      "progress: 83.87%\n",
      "progress: 84.92%\n",
      "progress: 85.97%\n",
      "progress: 87.02%\n",
      "progress: 88.07%\n",
      "progress: 89.12%\n",
      "progress: 90.16%\n",
      "progress: 91.21%\n",
      "progress: 92.26%\n",
      "progress: 93.31%\n",
      "progress: 94.36%\n",
      "progress: 95.41%\n",
      "progress: 96.46%\n",
      "progress: 97.50%\n",
      "progress: 98.55%\n",
      "progress: 99.60%\n"
     ]
    }
   ],
   "source": [
    "# get position from tsne\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'rb') as f:\n",
    "    xml = f.read()\n",
    "    tree = etree.parse(BytesIO(xml))\n",
    "    \n",
    "f_len = 0\n",
    "i = 0\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_tsne3dim.csv', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        f_len+=1\n",
    "\n",
    "print('items:',f_len)\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_tsne3dim.csv', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if (i+1)%100 == 0:\n",
    "            print(\"progress: %.2f\" % (i * 100 / f_len) + \"%\")\n",
    "        \n",
    "        if len(line)<10:\n",
    "            continue\n",
    "            i += 1\n",
    "        line = line.strip(\"\\n\") # appid10,43.68485200657752,17.50947333605341,12.692957234610187\n",
    "        split = line.split(',')\n",
    "        if len(split)!=4:\n",
    "            print('line seems errorenous:',line)\n",
    "            continue\n",
    "        appid = split[0]\n",
    "        appid = appid.strip('appid')\n",
    "        #print(appid)\n",
    "        app = tree.xpath('//app[@id=\"'+str(appid)+'\"]')[0]\n",
    "        query = app.xpath(\".//positions\")\n",
    "        if len(query) == 0:\n",
    "            sub = etree.SubElement(app, 'positions')\n",
    "        else:\n",
    "            sub = query[0]\n",
    "        query = sub.xpath(\".//position[@type='tsne']\")\n",
    "        if len(query) == 0:\n",
    "            sub2 = etree.SubElement(sub, 'position')\n",
    "            sub2.set('type','tsne')\n",
    "        else:\n",
    "            sub2 = query[0]\n",
    "        sub2.set('x',split[1])\n",
    "        sub2.set('y',split[2])\n",
    "        sub2.set('z',split[3])\n",
    "            \n",
    "        i += 1\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\GamesGraph\\\\scripts\\\\wip_data\\\\_working.xml', 'wb') as f:\n",
    "    f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
